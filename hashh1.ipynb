{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26c96c16",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "26c96c16",
    "outputId": "0fb6ef11-77b7-4b6a-db68-519a434936a1"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "048978ff",
   "metadata": {
    "id": "048978ff"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.text import hashing_trick\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import random\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "zJykvf1ECM9i",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zJykvf1ECM9i",
    "outputId": "cac9b7a7-56ce-410a-c8d9-42d0031363b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1300 200 130 24\n"
     ]
    }
   ],
   "source": [
    "wynik1 = round(random.randint(200, 2000), -2)\n",
    "wynik2 = round(random.randint(100, 1500), -2)\n",
    "wynik3 = round(random.randint(20, 200), -1)\n",
    "num_epochs = round(random.randint(10, 40), 0)\n",
    "\n",
    "batchsize = 500\n",
    "\n",
    "print(wynik1, wynik2, wynik3, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56ef4fde",
   "metadata": {
    "id": "56ef4fde"
   },
   "outputs": [],
   "source": [
    "metrics = [keras.metrics.TruePositives(name='tp'),\n",
    "           keras.metrics.FalsePositives(name='fp'),\n",
    "           keras.metrics.TrueNegatives(name='tn'),\n",
    "           keras.metrics.FalseNegatives(name='fn'),\n",
    "           keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "           keras.metrics.Precision(name='precision'),\n",
    "           keras.metrics.Recall(name='recall'),\n",
    "           keras.metrics.AUC(name='auc')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c15a04bf",
   "metadata": {
    "id": "c15a04bf"
   },
   "outputs": [],
   "source": [
    "t=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fbaab8e",
   "metadata": {
    "id": "6fbaab8e"
   },
   "outputs": [],
   "source": [
    "dset = pd.read_csv('data/probkauczaca2.csv', sep=';',encoding='utf-8')\n",
    "\n",
    "Y = dset['Default'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "020fbbc0",
   "metadata": {
    "id": "020fbbc0"
   },
   "outputs": [],
   "source": [
    "vartype =  pd.read_excel('data/rodzaje_zmiennych.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9449d419",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9449d419",
    "outputId": "fea0e995-8681-465f-a762-f9ac6c42171b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Przychody', 'Suma_bilansowa', 'CNT_WPPLN', 'CNT_OWPLN', 'CNT_WKPLN', 'OWPRC', 'WKPRC', 'MARZA', 'Admin', 'PROWIZJA', 'Kapital']\n",
      "['Default', 'Czy_cesja', 'Czy_leasing_zwrotny', 'Wynik_sprawdzen_KRD']\n",
      "['Liczba_prawcownikow', 'Rok_produkcji', 'Okres_umowy', 'CzasDzialalnosciMce']\n",
      "['OBT_Type2', 'OBT_IFNEW', 'Czy_autoryzowany_dostawca', 'Waluta', 'Rodzaj_harmonogramu', 'Rodzaj_oprocentowania', 'Dodatkowe_zabezpieczenie_transakcji', 'Kanal_pozyskania', 'Oddzial', 'Rodzaj_umowy', 'Procedura', 'PKD_2007', 'PROW_Z_MARZY', 'forma_prawna', 'Grupowanie_form_prawnych']\n"
     ]
    }
   ],
   "source": [
    "columnX=[]\n",
    "X_binary = []\n",
    "X_discrete = []\n",
    "X_text_cat = []\n",
    "for i in range(vartype.shape[1]):\n",
    "    if vartype.iloc[0][i] == \"numeric_continuous\":\n",
    "        columnX.append(dset.columns[i])\n",
    "    if vartype.iloc[0][i] == \"numeric_binary\":\n",
    "        X_binary.append(dset.columns[i])\n",
    "    if vartype.iloc[0][i] == \"numeric_discrete\":\n",
    "        X_discrete.append(dset.columns[i])\n",
    "    if vartype.iloc[0][i] == \"text_categorical\":\n",
    "        X_text_cat.append(dset.columns[i])\n",
    "\n",
    "print(columnX)\n",
    "print(X_binary)\n",
    "print(X_discrete)\n",
    "print(X_text_cat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01104a0b",
   "metadata": {
    "id": "01104a0b"
   },
   "outputs": [],
   "source": [
    "X = dset.loc[:, columnX].astype(float)\n",
    "X['Kapital'] = X['Kapital'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54b39c17",
   "metadata": {
    "id": "54b39c17"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "# Standaryzacja wszystkich zmiennych w dataframe X\n",
    "X_standardized = scaler.fit_transform(X)\n",
    "# Tworzenie nowego dataframe z zstandaryzowanymi danymi\n",
    "X_standardized_df = pd.DataFrame(X_standardized, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "418621ec",
   "metadata": {
    "id": "418621ec"
   },
   "outputs": [],
   "source": [
    "# Tworzenie obiektu MinMaxScaler\n",
    "scaler_minmax = MinMaxScaler()\n",
    "\n",
    "# Normalizacja min-max dla zmiennych z X_discrete\n",
    "for column_name in X_discrete:\n",
    "    dset[column_name] = scaler_minmax.fit_transform(dset[[column_name]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04a9513b",
   "metadata": {
    "id": "04a9513b"
   },
   "outputs": [],
   "source": [
    "X_bin = dset.loc[:,['Czy_cesja', 'Czy_leasing_zwrotny', 'Wynik_sprawdzen_KRD']].astype(str)\n",
    "X_yesno = pd.DataFrame(X_bin['Czy_cesja'].eq('1').mul(1))\n",
    "#X_yesno = pd.DataFrame(X_binary['OBT_IFNEW'].eq('New').mul(1))\n",
    "#X_yesno['Czy_aut_dostawca'] = X_binary['Czy_autoryzowany_dostawca'].eq('T').mul(1)\n",
    "#X_yesno['Waluta'] = X_binary['Waluta'].eq('PLN').mul(1)\n",
    "#X_yesno['Rodzaj_harm'] = X_binary['Rodzaj_harmonogramu'].eq('liniowy').mul(1)\n",
    "#X_yesno['Rodzaj_oproc'] = X_binary['Rodzaj_oprocentowania'].eq('V').mul(1)\n",
    "##X_yesno['Dodat_zabezp_trans'] = X_binary['Dodatkowe_zabezpieczenie_transakcji'].eq('WEKSEL').mul(1)\n",
    "#X_yesno['Kanal_pozysk'] = X_binary['Kanal_pozyskania'].eq('Porednik').mul(1)\n",
    "#X_yesno['Cesja'] = X_bin['Czy_cesja'].eq('1').mul(1)\n",
    "#X_yesno['Auto_luks'] = X_binary['Auto_luksusowe'].eq('1').mul(1)\n",
    "#X_yesno['RSEUO'] = X_binary['RS_EUO'].eq('1').mul(1)\n",
    "#X_yesno['BiuroWirtK'] = X_binary['BiuroWirtualneKlient'].eq('1').mul(1)\n",
    "#X_yesno['BiuroWirtD'] = X_binary['BiuroWirtualneDostawca'].eq('1').mul(1)\n",
    "#X_yesno['BiuroWirtP'] = X_binary['BiuroWirtualnePosrednik'].eq('1').mul(1)\n",
    "X_yesno['Czy_leas_zwr'] = X_bin['Czy_leasing_zwrotny'].astype(float)\n",
    "X_yesno['Wyn_spraw_KRD'] = X_bin['Wynik_sprawdzen_KRD'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b320d86f",
   "metadata": {
    "id": "b320d86f"
   },
   "outputs": [],
   "source": [
    "# ----- ładowanie danych głównego kodu PKD ------\n",
    "# w tym przypadku wykorzystywane są tylko fragmenty PKD /sekcja, dział, grupa/\n",
    "\n",
    "#dodać zmienną x_text_kat - zrobione\n",
    "\n",
    "#zaminić dset na zmienną X_text_cat - zrobić!\n",
    "\n",
    "#X_text_cat['kodpkd'] = X_text_cat['PKD_2007'].str.get(0)+X_text_cat['PKD_2007'].str.get(1)+X_text_cat['PKD_2007'].str.get(2)\n",
    "dset['kodpkd'] = dset['PKD_2007'].str.get(0)+dset['PKD_2007'].str.get(1)+dset['PKD_2007'].str.get(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3cba5597",
   "metadata": {
    "id": "3cba5597"
   },
   "outputs": [],
   "source": [
    "# ---- ładowanie danych rodzaj umowy; oddział; grupowanie form prawnych; branza; OBT_Type2 (czyli rodzaj przedmiotu lisingu)\n",
    "#zaminić dset na zmienną X_text_cat - zrobić\n",
    "dset['rodzumowy'] = dset['Rodzaj_umowy'].astype(str)\n",
    "dset['oddzial1'] = dset['Oddzial'].astype(str)\n",
    "dset['oddzial1'] = dset['oddzial1'].str.replace(' ', '')\n",
    "dset['oddzial1'] = dset['oddzial1'].str.replace('-', '')\n",
    "dset['oddzial1'] = dset['oddzial1'].str.strip()\n",
    "dset['grupowanie'] = dset['Grupowanie_form_prawnych'].astype(str)\n",
    "dset['branza1'] = dset['Branza'].astype(str)\n",
    "dset['OBT_Type2'] = dset['OBT_Type2'].str.replace(' ', '')\n",
    "dset['OBT_Type2'] = dset['OBT_Type2'].str.replace('&', '')\n",
    "\n",
    "#X_text_cat['rodzumowy'] = X_text_cat['Rodzaj_umowy'].astype(str)\n",
    "#X_text_cat['oddzial1'] = X_text_cat['Oddzial'].astype(str)\n",
    "#X_text_cat['oddzial1'] = X_text_cat['oddzial1'].str.replace(' ', '')\n",
    "#X_text_cat['oddzial1'] = X_text_cat['oddzial1'].str.replace('-', '')\n",
    "#X_text_cat['oddzial1'] = X_text_cat['oddzial1'].str.strip()\n",
    "#X_text_cat['grupowanie'] = X_text_cat['Grupowanie_form_prawnych'].astype(str)\n",
    "#X_text_cat['branza1'] = X_text_cat['Branza'].astype(str)\n",
    "#X_text_cat['OBT_Type2'] = X_text_cat['OBT_Type2'].str.replace(' ', '')\n",
    "#X_text_cat['OBT_Type2'] = X_text_cat['OBT_Type2'].str.replace('&', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "877a8bda",
   "metadata": {
    "id": "877a8bda"
   },
   "outputs": [],
   "source": [
    "# ---- ładowanie danych z bazy danych z tabeli cechy scoringowe\n",
    "#X_scor = pd.DataFrame(dset.iloc[:, 35:92].values.astype(int)) # 57 kolumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74123a1f",
   "metadata": {
    "id": "74123a1f"
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(data, column, size):\n",
    "    encoder = OneHotEncoder(sparse_output=False)\n",
    "    encoded_data = encoder.fit_transform(data[[column]])\n",
    "    encoded_df = pd.DataFrame(encoded_data, columns=[f'{column}_{i}' for i in range(encoded_data.shape[1])])\n",
    "    return encoded_df\n",
    "\n",
    "def apply_hash(data, column, size):\n",
    "    encoded_hash = [hash(str(d)) % size for d in data[column]]\n",
    "    encoded_hash_df = pd.DataFrame(encoded_hash, columns=[f'{column}_hash'])\n",
    "    return encoded_hash_df\n",
    "\n",
    "# One-Hot Encoding dla 'pkd'\n",
    "pkd_size = 272\n",
    "X_pkd = one_hot_encode(dset, 'kodpkd', pkd_size)\n",
    "\n",
    "# Hashing Trick dla 'pkd'\n",
    "X_pkd_hash = apply_hash(dset, 'kodpkd', pkd_size)\n",
    "\n",
    "# One-Hot Encoding dla 'rodzumowy'\n",
    "rumowy_size = 4\n",
    "X_rumowy = one_hot_encode(dset, 'rodzumowy', rumowy_size)\n",
    "\n",
    "# Hashing Trick dla 'rodzumowy'\n",
    "X_rumowy_hash = apply_hash(dset, 'rodzumowy', rumowy_size)\n",
    "\n",
    "# One-Hot Encoding dla 'grupowanie'\n",
    "grupowanie_size = 4\n",
    "X_grupowanie = one_hot_encode(dset, 'grupowanie', grupowanie_size)\n",
    "\n",
    "# Hashing Trick dla 'grupowanie'\n",
    "X_grupowanie_hash = apply_hash(dset, 'grupowanie', grupowanie_size)\n",
    "\n",
    "# One-Hot Encoding dla 'oddzial1'\n",
    "oddzial1_size = 24\n",
    "X_oddzial1 = one_hot_encode(dset, 'oddzial1', oddzial1_size)\n",
    "\n",
    "# Hashing Trick dla 'oddzial1'\n",
    "X_oddzial1_hash = apply_hash(dset, 'oddzial1', oddzial1_size)\n",
    "\n",
    "# One-Hot Encoding dla 'branza1'\n",
    "branza1_size = 7\n",
    "X_branza1 = one_hot_encode(dset, 'branza1', branza1_size)\n",
    "\n",
    "# Hashing Trick dla 'branza1'\n",
    "X_branza1_hash = apply_hash(dset, 'branza1', branza1_size)\n",
    "\n",
    "# One-Hot Encoding dla 'OBT_Type2'\n",
    "objlise_size = 7\n",
    "X_objlise = one_hot_encode(dset, 'OBT_Type2', objlise_size)\n",
    "\n",
    "# Hashing Trick dla 'OBT_Type2'\n",
    "X_objlise_hash = apply_hash(dset, 'OBT_Type2', objlise_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f431df0a",
   "metadata": {
    "id": "f2664bed"
   },
   "outputs": [],
   "source": [
    "tdset = pd.read_csv('data/probkatestowa2.csv', sep=';',encoding='utf-8')\n",
    "del tdset['Data_bilansowa']\n",
    "\n",
    "tY = tdset['Default'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58a86b5d",
   "metadata": {
    "id": "58a86b5d"
   },
   "outputs": [],
   "source": [
    "#print(tdset)\n",
    "\n",
    "tX = tdset.loc[:, columnX].astype(float)\n",
    "# usuwa Null z 3 kolumn\n",
    "\n",
    "tX['Kapital'] = tX['Kapital'].fillna(0)\n",
    "\n",
    "tscaler = StandardScaler()\n",
    "\n",
    "# Standaryzacja wszystkich zmiennych w dataframe X\n",
    "tX_standardized = scaler.fit_transform(tX)\n",
    "# Tworzenie nowego dataframe z zstandaryzowanymi danymi\n",
    "tX_standardized_df = pd.DataFrame(tX_standardized, columns=tX.columns)\n",
    "\n",
    "# Tworzenie obiektu MinMaxScaler\n",
    "tscaler_minmax = MinMaxScaler()\n",
    "\n",
    "# Normalizacja min-max dla zmiennych z X_discrete\n",
    "for column_name in X_discrete:\n",
    "    tdset[column_name] = scaler_minmax.fit_transform(tdset[[column_name]])\n",
    "\n",
    "tX_bin = tdset.loc[:,['Czy_cesja', 'Czy_leasing_zwrotny', 'Wynik_sprawdzen_KRD']].astype(str)\n",
    "\n",
    "tX_yesno = pd.DataFrame(tX_bin['Czy_cesja'].eq('1').mul(1))\n",
    "#tX_yesno['Czy_aut_dostawca'] = tX_binary['Czy_autoryzowany_dostawca'].eq('T').mul(1)\n",
    "#tX_yesno['Waluta'] = tX_binary['Waluta'].eq('PLN').mul(1)\n",
    "#tX_yesno['Rodzaj_harm'] = tX_binary['Rodzaj_harmonogramu'].eq('liniowy').mul(1)\n",
    "#tX_yesno['Rodzaj_oproc'] = tX_binary['Rodzaj_oprocentowania'].eq('V').mul(1)\n",
    "#tX_yesno['Dodat_zabezp_trans'] = tX_binary['Dodatkowe_zabezpieczenie_transakcji'].eq('WEKSEL').mul(1)\n",
    "#tX_yesno['Kanal_pozysk'] = tX_binary['Kanal_pozyskania'].eq('Porednik').mul(1)\n",
    "#tX_yesno['Cesja'] = tX_bin['Czy_cesja'].eq('1').mul(1)\n",
    "#tX_yesno['Auto_luks'] = tX_binary['Auto_luksusowe'].eq('1').mul(1)\n",
    "#tX_yesno['RSEUO'] = tX_binary['RS_EUO'].eq('1').mul(1)\n",
    "#tX_yesno['BiuroWirtK'] = tX_binary['BiuroWirtualneKlient'].eq('1').mul(1)\n",
    "#tX_yesno['BiuroWirtD'] = tX_binary['BiuroWirtualneDostawca'].eq('1').mul(1)\n",
    "#tX_yesno['BiuroWirtP'] = tX_binary['BiuroWirtualnePosrednik'].eq('1').mul(1)\n",
    "tX_yesno['Czy_leas_zwr'] = tX_bin['Czy_leasing_zwrotny'].astype(float)\n",
    "tX_yesno['Wyn_spraw_KRD'] = tX_bin['Wynik_sprawdzen_KRD'].astype(float)\n",
    "tdset['kodpkd'] = tdset['PKD_2007'].str.get(0)+tdset['PKD_2007'].str.get(1)+tdset['PKD_2007'].str.get(2)\n",
    "\n",
    "tdset['rodzumowy'] = tdset['Rodzaj_umowy'].astype(str)\n",
    "tdset['oddzial1'] = tdset['Oddzial'].astype(str)\n",
    "tdset['oddzial1'] = tdset['oddzial1'].str.replace(' ', '')\n",
    "tdset['oddzial1'] = tdset['oddzial1'].str.replace('-', '')\n",
    "tdset['oddzial1'] = tdset['oddzial1'].str.strip()\n",
    "tdset['grupowanie'] = tdset['Grupowanie_form_prawnych'].astype(str)\n",
    "tdset['branza1'] = tdset['Branza'].astype(str)\n",
    "tdset['OBT_Type2'] = tdset['OBT_Type2'].str.replace(' ', '')\n",
    "tdset['OBT_Type2'] = tdset['OBT_Type2'].str.replace('&', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6d2794f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(data, column, size):\n",
    "    encoder = OneHotEncoder(sparse_output=False)\n",
    "    encoded_data = encoder.fit_transform(data[[column]])\n",
    "    encoded_df = pd.DataFrame(encoded_data, columns=[f'{column}_{i}' for i in range(encoded_data.shape[1])])\n",
    "    return encoded_df\n",
    "\n",
    "def apply_hash(data, column, size):\n",
    "    encoded_hash = [hash(str(d)) % size for d in data[column]]\n",
    "    encoded_hash_df = pd.DataFrame(encoded_hash, columns=[f'{column}_hash'])\n",
    "    return encoded_hash_df\n",
    "\n",
    "# One-Hot Encoding dla 'pkd'\n",
    "tX_pkd = one_hot_encode(dset, 'kodpkd', pkd_size)\n",
    "\n",
    "# Hashing Trick dla 'pkd'\n",
    "tX_pkd_hash = apply_hash(dset, 'kodpkd', pkd_size)\n",
    "\n",
    "# One-Hot Encoding dla 'rodzumowy'\n",
    "tX_rumowy = one_hot_encode(dset, 'rodzumowy', rumowy_size)\n",
    "\n",
    "# Hashing Trick dla 'rodzumowy'\n",
    "tX_rumowy_hash = apply_hash(dset, 'rodzumowy', rumowy_size)\n",
    "\n",
    "# One-Hot Encoding dla 'grupowanie'\n",
    "tX_grupowanie = one_hot_encode(dset, 'grupowanie', grupowanie_size)\n",
    "\n",
    "# Hashing Trick dla 'grupowanie'\n",
    "tX_grupowanie_hash = apply_hash(dset, 'grupowanie', grupowanie_size)\n",
    "\n",
    "# One-Hot Encoding dla 'oddzial1'\n",
    "tX_oddzial1 = one_hot_encode(dset, 'oddzial1', oddzial1_size)\n",
    "\n",
    "# Hashing Trick dla 'oddzial1'\n",
    "tX_oddzial1_hash = apply_hash(dset, 'oddzial1', oddzial1_size)\n",
    "\n",
    "# One-Hot Encoding dla 'branza1'\n",
    "tX_branza1 = one_hot_encode(dset, 'branza1', branza1_size)\n",
    "\n",
    "# Hashing Trick dla 'branza1'\n",
    "tX_branza1_hash = apply_hash(dset, 'branza1', branza1_size)\n",
    "\n",
    "# One-Hot Encoding dla 'OBT_Type2'\n",
    "tX_objlise = one_hot_encode(dset, 'OBT_Type2', objlise_size)\n",
    "\n",
    "# Hashing Trick dla 'OBT_Type2'\n",
    "tX_objlise_hash = apply_hash(dset, 'OBT_Type2', objlise_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "05831812",
   "metadata": {
    "id": "05831812"
   },
   "outputs": [],
   "source": [
    "#------------------------ Model sztucznej sieci neuronowej (ANN)-----------------------------------------------------------\n",
    "\n",
    "\n",
    "inputpkd = Input(shape=(1,), name='in_pkd')\n",
    "pkd = Embedding(pkd_size, 10, input_length=1)(inputpkd)\n",
    "pkd_out = Flatten()(pkd)\n",
    "pkd_out = Dense(200, activation='relu')(pkd_out)\n",
    "\n",
    "inputrumowy = Input(shape=(1,), name='in_rodzaj_umowy')\n",
    "rumowy = Embedding(rumowy_size, 3, input_length=1)(inputrumowy)\n",
    "rumowy_out = Flatten()(rumowy)\n",
    "rumowy_out = Dense(100, activation='relu')(rumowy_out)\n",
    "\n",
    "inputgrupowanie = Input(shape=(1,), name='in_grupowanie')\n",
    "grupowanie = Embedding(grupowanie_size, 3, input_length=1)(inputgrupowanie)\n",
    "grupowanie_out = Flatten()(grupowanie)\n",
    "grupowanie_out = Dense(100, activation='relu')(grupowanie_out)\n",
    "\n",
    "inputoddzial1 = Input(shape=(1,), name='in_oddzial1')\n",
    "oddzial1 = Embedding(oddzial1_size, 10, input_length=1)(inputoddzial1)\n",
    "oddzial1_out = Flatten()(oddzial1)\n",
    "oddzial1_out = Dense(100, activation='relu')(oddzial1_out)\n",
    "\n",
    "inputbranza1 = Input(shape=(1,), name='in_branza1')\n",
    "branza1 = Embedding(branza1_size, 4, input_length=1)(inputbranza1)\n",
    "branza1_out = Flatten()(branza1)\n",
    "branza1_out = Dense(100, activation='relu')(branza1_out)\n",
    "\n",
    "inputobjlise = Input(shape=(1,), name='in_lise_object')\n",
    "objlise = Embedding(objlise_size, 4, input_length=1)(inputobjlise)\n",
    "objlise_out = Flatten()(objlise)\n",
    "objlise_out = Dense(100, activation='relu')(objlise_out)\n",
    "\n",
    "inputnumbers = Input(shape=(11,), name='in_continous')\n",
    "innum = Dense(200, activation=\"relu\")(inputnumbers)\n",
    "innum = BatchNormalization()(innum)\n",
    "num_out = Dense(100, activation=\"relu\")(innum)\n",
    "\n",
    "inputyesno = Input(shape=(3,), name='in_bool')\n",
    "inyesno = Dense(15, activation=\"relu\")(inputyesno)\n",
    "yesno_out = Dense(10, activation=\"relu\")(inyesno)\n",
    "\n",
    "#inputscor = Input(shape=(57,), name='in_scoring')\n",
    "#scor = Embedding(scor_size, 10, input_length=57)(inputscor)\n",
    "#scor_out = Flatten()(scor)\n",
    "#scor_out = Dense(400, activation='relu')(scor_out)\n",
    "\n",
    "#inputcat = Input(shape=(322,), name='in_categorical')\n",
    "#catcode = Dense(1000, activation=\"relu\")(inputcat)\n",
    "#cat_out = Dense(100, activation='relu')(catcode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7750e3e0",
   "metadata": {
    "id": "7750e3e0"
   },
   "outputs": [],
   "source": [
    "merge = concatenate([pkd_out, num_out,rumowy_out,grupowanie_out, yesno_out, oddzial1_out, branza1_out, objlise_out], axis=-1)\n",
    "\n",
    "hidden = Dense(wynik1, activation='relu')(merge)\n",
    "hidden = BatchNormalization()(hidden)\n",
    "hidden = Dense(wynik2, activation='relu')(hidden)\n",
    "hidden = Dense(wynik3, activation='relu')(hidden)\n",
    "output = Dense(1, activation='sigmoid')(hidden)\n",
    "\n",
    "model = Model(inputs=[inputpkd,  inputnumbers, inputrumowy, inputgrupowanie, inputyesno, inputoddzial1,  inputbranza1, inputobjlise], outputs=output)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e50f3c7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8e50f3c7",
    "outputId": "2bed8226-c8eb-4677-ac9f-eeff77d0310f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " in_pkd (InputLayer)         [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " in_continous (InputLayer)   [(None, 11)]                 0         []                            \n",
      "                                                                                                  \n",
      " in_rodzaj_umowy (InputLaye  [(None, 1)]                  0         []                            \n",
      " r)                                                                                               \n",
      "                                                                                                  \n",
      " in_grupowanie (InputLayer)  [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " in_oddzial1 (InputLayer)    [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " in_branza1 (InputLayer)     [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " in_lise_object (InputLayer  [(None, 1)]                  0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, 1, 10)                2720      ['in_pkd[0][0]']              \n",
      "                                                                                                  \n",
      " dense_6 (Dense)             (None, 200)                  2400      ['in_continous[0][0]']        \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)     (None, 1, 3)                 12        ['in_rodzaj_umowy[0][0]']     \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)     (None, 1, 3)                 12        ['in_grupowanie[0][0]']       \n",
      "                                                                                                  \n",
      " in_bool (InputLayer)        [(None, 3)]                  0         []                            \n",
      "                                                                                                  \n",
      " embedding_3 (Embedding)     (None, 1, 10)                240       ['in_oddzial1[0][0]']         \n",
      "                                                                                                  \n",
      " embedding_4 (Embedding)     (None, 1, 4)                 28        ['in_branza1[0][0]']          \n",
      "                                                                                                  \n",
      " embedding_5 (Embedding)     (None, 1, 4)                 28        ['in_lise_object[0][0]']      \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 10)                   0         ['embedding[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 200)                  800       ['dense_6[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)         (None, 3)                    0         ['embedding_1[0][0]']         \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)         (None, 3)                    0         ['embedding_2[0][0]']         \n",
      "                                                                                                  \n",
      " dense_8 (Dense)             (None, 15)                   60        ['in_bool[0][0]']             \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)         (None, 10)                   0         ['embedding_3[0][0]']         \n",
      "                                                                                                  \n",
      " flatten_4 (Flatten)         (None, 4)                    0         ['embedding_4[0][0]']         \n",
      "                                                                                                  \n",
      " flatten_5 (Flatten)         (None, 4)                    0         ['embedding_5[0][0]']         \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 200)                  2200      ['flatten[0][0]']             \n",
      "                                                                                                  \n",
      " dense_7 (Dense)             (None, 100)                  20100     ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 100)                  400       ['flatten_1[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 100)                  400       ['flatten_2[0][0]']           \n",
      "                                                                                                  \n",
      " dense_9 (Dense)             (None, 10)                   160       ['dense_8[0][0]']             \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 100)                  1100      ['flatten_3[0][0]']           \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 100)                  500       ['flatten_4[0][0]']           \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 100)                  500       ['flatten_5[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 810)                  0         ['dense[0][0]',               \n",
      "                                                                     'dense_7[0][0]',             \n",
      "                                                                     'dense_1[0][0]',             \n",
      "                                                                     'dense_2[0][0]',             \n",
      "                                                                     'dense_9[0][0]',             \n",
      "                                                                     'dense_3[0][0]',             \n",
      "                                                                     'dense_4[0][0]',             \n",
      "                                                                     'dense_5[0][0]']             \n",
      "                                                                                                  \n",
      " dense_10 (Dense)            (None, 1300)                 1054300   ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (None, 1300)                 5200      ['dense_10[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dense_11 (Dense)            (None, 200)                  260200    ['batch_normalization_1[0][0]'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dense_12 (Dense)            (None, 130)                  26130     ['dense_11[0][0]']            \n",
      "                                                                                                  \n",
      " dense_13 (Dense)            (None, 1)                    131       ['dense_12[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1377621 (5.26 MB)\n",
      "Trainable params: 1374621 (5.24 MB)\n",
      "Non-trainable params: 3000 (11.72 KB)\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf6e2b1e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cf6e2b1e",
    "outputId": "1b696218-dba2-47ed-e9cd-86c67eabbf09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 11)\n",
      "[(None, 1)]\n",
      "2.13.0\n"
     ]
    }
   ],
   "source": [
    "# Sprawdź kształt danych wejściowych\n",
    "print(X.shape)\n",
    "\n",
    "# Sprawdź wartość argumentu `input_shape` dla warstwy `Dense`\n",
    "print(model.layers[0].input_shape)\n",
    "\n",
    "# Sprawdź wersję TensorFlow\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d049cc53",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d049cc53",
    "outputId": "ef42a106-2fc2-4c5f-9dd4-0c4e87035fcf"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 3436 and the array at index 1 has size 10000",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Powtórzenie tego samego procesu dla tablic tX\u001b[39;00m\n\u001b[0;32m      9\u001b[0m t_arrays \u001b[38;5;241m=\u001b[39m [tX, tX_pkd, tX_pkd_hash, tX_rumowy, tX_rumowy_hash, tX_grupowanie, tX_grupowanie_hash, tX_oddzial1, tX_oddzial1_hash, tX_branza1, tX_branza1_hash, tX_objlise, tX_objlise_hash]\n\u001b[1;32m---> 10\u001b[0m tX_combined \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(t_arrays, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# One-Hot Encoding\u001b[39;00m\n\u001b[0;32m     13\u001b[0m encoder \u001b[38;5;241m=\u001b[39m OneHotEncoder()\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 3436 and the array at index 1 has size 10000"
     ]
    }
   ],
   "source": [
    "# Definiowanie tablic do połączenia\n",
    "arrays = [X, X_pkd, X_pkd_hash, X_rumowy, X_rumowy_hash, X_grupowanie, X_grupowanie_hash, X_oddzial1, X_oddzial1_hash, X_branza1, X_branza1_hash, X_objlise, X_objlise_hash]\n",
    "\n",
    "# Łączenie tablic wzdłuż drugiej osi\n",
    "X_combined = np.concatenate(arrays, axis=1)\n",
    "\n",
    "tX_resized = np.resize(tX, (X.shape[0], tX.shape[1]))\n",
    "# Powtórzenie tego samego procesu dla tablic tX\n",
    "t_arrays = [tX, tX_pkd, tX_pkd_hash, tX_rumowy, tX_rumowy_hash, tX_grupowanie, tX_grupowanie_hash, tX_oddzial1, tX_oddzial1_hash, tX_branza1, tX_branza1_hash, tX_objlise, tX_objlise_hash]\n",
    "tX_combined = np.concatenate(t_arrays, axis=1)\n",
    "\n",
    "# One-Hot Encoding\n",
    "encoder = OneHotEncoder()\n",
    "encoder.fit(X_combined)\n",
    "X_encoded = encoder.transform(X_combined)\n",
    "tX_encoded = encoder.transform(tX_combined)\n",
    "\n",
    "# Podział danych na zbiór treningowy i walidacyjny\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_encoded, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tworzenie modelu\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(X_encoded.shape[1],)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Kompilacja modelu\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Trenowanie modelu\n",
    "start_time = time.time()\n",
    "model.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs=num_epochs, batch_size=batchsize)\n",
    "\n",
    "# Zapis modelu\n",
    "model.save_weights(\"model3_weights.h5\", overwrite=True)\n",
    "model.save('model3_structure.h5', overwrite=True)\n",
    "\n",
    "# Wyświetlenie czasu symulacji\n",
    "print(\"Czas symulacji:\", time.time() - start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24967b7b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "24967b7b",
    "outputId": "efc8ec26-0f70-41b1-aa72-da8e2dbb3514"
   },
   "outputs": [],
   "source": [
    "model.save_weights(\"model3_weights.h5\", overwrite=True)\n",
    "model.save('model3_structure.h5', overwrite=True)\n",
    "print(\"Czas symulacji: \", time.time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4AK4W6KGDEoS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4AK4W6KGDEoS",
    "outputId": "dfd1afa5-bc3e-423d-9d78-202c0bc1c6b7"
   },
   "outputs": [],
   "source": [
    "####użyć tylko raz, jak następny kod nie działa !!\n",
    "#df = pd.DataFrame()\n",
    "#file_name = 'wyniki_treningu.xlsx'\n",
    "#df.to_excel(file_name, index=False)\n",
    "#print(f\"Plik {file_name} został utworzony.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ghMUFxaaDOU_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ghMUFxaaDOU_",
    "outputId": "3d26e129-4f59-4229-e214-0dc7ed0d8011"
   },
   "outputs": [],
   "source": [
    "training_results = []\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    epoch_results = {\n",
    "        'loss': h.history['loss'][i],\n",
    "        'val_loss': h.history['val_loss'][i],\n",
    "        'val_accuracy': h.history['val_accuracy'][i],\n",
    "        'val_precision': h.history['val_precision'][i],\n",
    "        'val_recall': h.history['val_recall'][i],\n",
    "        'val_auc': h.history['val_auc'][i],\n",
    "        'czas_symulacji': time.time() - t\n",
    "    }\n",
    "\n",
    "    training_results.append(epoch_results)\n",
    "\n",
    "results_df = pd.DataFrame(training_results)\n",
    "\n",
    "title_epochs = f\"Wyniki treningu dla {num_epochs} epok\"\n",
    "title_1 = f\"Dense 1: {wynik1}\"\n",
    "title_2 = f\"Dense 2: {wynik2}\"\n",
    "title_3 = f\"Dense 3: {wynik3}\"\n",
    "\n",
    "sheet_name = f'Sheet_{int(time.time())}'\n",
    "\n",
    "with pd.ExcelWriter('wyniki_treningu.xlsx', engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    results_df.to_excel(writer, index=False, sheet_name=sheet_name)\n",
    "\n",
    "    worksheet = writer.sheets[sheet_name]\n",
    "\n",
    "    worksheet.cell(row=1, column=22, value=title_epochs)\n",
    "    worksheet.cell(row=2, column=22, value=title_1)\n",
    "    worksheet.cell(row=3, column=22, value=title_2)\n",
    "    worksheet.cell(row=4, column=22, value=title_3)\n",
    "\n",
    "print(results_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6bdab4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 537
    },
    "id": "9c6bdab4",
    "outputId": "078282fd-2e0f-4627-c9c2-022499facf00"
   },
   "outputs": [],
   "source": [
    "# dodatkowe elementy (można zakomentować); rysowanie wykresu dokładności ANN; Dokładnośc ANN dla Defaultów\n",
    "plt.plot(h.history['val_accuracy'])\n",
    "\n",
    "#plt.plot(h.history['accuracy'])\n",
    "\n",
    "#plt.plot(h.history['val_accuracy'])\n",
    "\n",
    "#plt.title('Model accuracy')\n",
    "\n",
    "#plt.ylabel('Accuracy')\n",
    "\n",
    "#plt.xlabel('Epoch')\n",
    "\n",
    "#plt.legend(['Train', 'Test'], loc='upper left')\n",
    "\n",
    "\n",
    "\n",
    "accuracy = model.evaluate([np.array(tX_pkd),np.array(tX), np.array(tX_rumowy), np.array(tX_grupowanie), np.array(tX_yesno),\n",
    "                           np.array(tX_oddzial1), np.array(tX_branza1), np.array(tX_objlise)], tY)\n",
    "print('Accuracy: %f' % (accuracy[1]))\n",
    "\n",
    "ypred = model.predict([np.array(tX_pkd),np.array(tX), np.array(tX_rumowy), np.array(tX_grupowanie), np.array(tX_yesno),\n",
    "                           np.array(tX_oddzial1), np.array(tX_branza1), np.array(tX_objlise)])\n",
    "\n",
    "count = 0\n",
    "total = 0\n",
    "for i in range(len(ypred)):\n",
    "    if tY[i] == 1:\n",
    "        total = total + 1\n",
    "        if ypred[i][0] > 0.5:\n",
    "            count = count + 1\n",
    "print(\"dokładność [1]: \", count/total)\n",
    "\n",
    "count = 0\n",
    "total = 0\n",
    "for i in range(len(ypred)):\n",
    "    if tY[i] == 0:\n",
    "        total = total + 1\n",
    "        if ypred[i][0] < 0.5:\n",
    "            count = count + 1\n",
    "print(\"dokładność [0]: \", count/total)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d5b9d6",
   "metadata": {
    "id": "45d5b9d6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655d6105",
   "metadata": {
    "id": "655d6105"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
