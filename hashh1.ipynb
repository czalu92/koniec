{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26c96c16",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "26c96c16",
    "outputId": "0fb6ef11-77b7-4b6a-db68-519a434936a1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "048978ff",
   "metadata": {
    "id": "048978ff",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.text import hashing_trick\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import random\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "zJykvf1ECM9i",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zJykvf1ECM9i",
    "outputId": "cac9b7a7-56ce-410a-c8d9-42d0031363b4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 1300 30 26\n"
     ]
    }
   ],
   "source": [
    "wynik1 = round(random.randint(200, 2000), -2)\n",
    "wynik2 = round(random.randint(100, 1500), -2)\n",
    "wynik3 = round(random.randint(20, 200), -1)\n",
    "num_epochs = round(random.randint(10, 40), 0)\n",
    "\n",
    "batchsize = 500\n",
    "\n",
    "print(wynik1, wynik2, wynik3, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56ef4fde",
   "metadata": {
    "id": "56ef4fde"
   },
   "outputs": [],
   "source": [
    "metrics = [keras.metrics.TruePositives(name='tp'),\n",
    "           keras.metrics.FalsePositives(name='fp'),\n",
    "           keras.metrics.TrueNegatives(name='tn'),\n",
    "           keras.metrics.FalseNegatives(name='fn'),\n",
    "           keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "           keras.metrics.Precision(name='precision'),\n",
    "           keras.metrics.Recall(name='recall'),\n",
    "           keras.metrics.AUC(name='auc')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c15a04bf",
   "metadata": {
    "id": "c15a04bf"
   },
   "outputs": [],
   "source": [
    "t=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fbaab8e",
   "metadata": {
    "id": "6fbaab8e"
   },
   "outputs": [],
   "source": [
    "dset = pd.read_csv('data/probkauczaca2.csv', sep=';',encoding='utf-8')\n",
    "\n",
    "Y = dset['Default'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "020fbbc0",
   "metadata": {
    "id": "020fbbc0"
   },
   "outputs": [],
   "source": [
    "vartype =  pd.read_excel('data/rodzaje_zmiennych.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9449d419",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9449d419",
    "outputId": "fea0e995-8681-465f-a762-f9ac6c42171b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Przychody', 'Suma_bilansowa', 'CNT_WPPLN', 'CNT_OWPLN', 'CNT_WKPLN', 'OWPRC', 'WKPRC', 'MARZA', 'Admin', 'PROWIZJA', 'Kapital']\n",
      "['Default', 'Czy_cesja', 'Czy_leasing_zwrotny', 'Wynik_sprawdzen_KRD']\n",
      "['Liczba_prawcownikow', 'Rok_produkcji', 'Okres_umowy', 'CzasDzialalnosciMce']\n",
      "['OBT_Type2', 'OBT_IFNEW', 'Czy_autoryzowany_dostawca', 'Waluta', 'Rodzaj_harmonogramu', 'Rodzaj_oprocentowania', 'Dodatkowe_zabezpieczenie_transakcji', 'Kanal_pozyskania', 'Oddzial', 'Rodzaj_umowy', 'Procedura', 'PKD_2007', 'PROW_Z_MARZY', 'forma_prawna', 'Grupowanie_form_prawnych']\n"
     ]
    }
   ],
   "source": [
    "columnX=[]\n",
    "X_binary = []\n",
    "X_discrete = []\n",
    "X_text_cat = []\n",
    "for i in range(vartype.shape[1]):\n",
    "    if vartype.iloc[0][i] == \"numeric_continuous\":\n",
    "        columnX.append(dset.columns[i])\n",
    "    if vartype.iloc[0][i] == \"numeric_binary\":\n",
    "        X_binary.append(dset.columns[i])\n",
    "    if vartype.iloc[0][i] == \"numeric_discrete\":\n",
    "        X_discrete.append(dset.columns[i])\n",
    "    if vartype.iloc[0][i] == \"text_categorical\":\n",
    "        X_text_cat.append(dset.columns[i])\n",
    "\n",
    "print(columnX)\n",
    "print(X_binary)\n",
    "print(X_discrete)\n",
    "print(X_text_cat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01104a0b",
   "metadata": {
    "id": "01104a0b"
   },
   "outputs": [],
   "source": [
    "X = dset.loc[:, columnX].astype(float)\n",
    "X['Kapital'] = X['Kapital'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54b39c17",
   "metadata": {
    "id": "54b39c17"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "# Standaryzacja wszystkich zmiennych w dataframe X\n",
    "X_standardized = scaler.fit_transform(X)\n",
    "# Tworzenie nowego dataframe z zstandaryzowanymi danymi\n",
    "X_standardized_df = pd.DataFrame(X_standardized, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "418621ec",
   "metadata": {
    "id": "418621ec"
   },
   "outputs": [],
   "source": [
    "# Tworzenie obiektu MinMaxScaler\n",
    "scaler_minmax = MinMaxScaler()\n",
    "\n",
    "# Normalizacja min-max dla zmiennych z X_discrete\n",
    "for column_name in X_discrete:\n",
    "    dset[column_name] = scaler_minmax.fit_transform(dset[[column_name]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04a9513b",
   "metadata": {
    "id": "04a9513b"
   },
   "outputs": [],
   "source": [
    "X_bin = dset.loc[:,['Czy_cesja', 'Czy_leasing_zwrotny', 'Wynik_sprawdzen_KRD']].astype(str)\n",
    "X_yesno = pd.DataFrame(X_bin['Czy_cesja'].eq('1').mul(1))\n",
    "#X_yesno = pd.DataFrame(X_binary['OBT_IFNEW'].eq('New').mul(1))\n",
    "#X_yesno['Czy_aut_dostawca'] = X_binary['Czy_autoryzowany_dostawca'].eq('T').mul(1)\n",
    "#X_yesno['Waluta'] = X_binary['Waluta'].eq('PLN').mul(1)\n",
    "#X_yesno['Rodzaj_harm'] = X_binary['Rodzaj_harmonogramu'].eq('liniowy').mul(1)\n",
    "#X_yesno['Rodzaj_oproc'] = X_binary['Rodzaj_oprocentowania'].eq('V').mul(1)\n",
    "##X_yesno['Dodat_zabezp_trans'] = X_binary['Dodatkowe_zabezpieczenie_transakcji'].eq('WEKSEL').mul(1)\n",
    "#X_yesno['Kanal_pozysk'] = X_binary['Kanal_pozyskania'].eq('Porednik').mul(1)\n",
    "#X_yesno['Cesja'] = X_bin['Czy_cesja'].eq('1').mul(1)\n",
    "#X_yesno['Auto_luks'] = X_binary['Auto_luksusowe'].eq('1').mul(1)\n",
    "#X_yesno['RSEUO'] = X_binary['RS_EUO'].eq('1').mul(1)\n",
    "#X_yesno['BiuroWirtK'] = X_binary['BiuroWirtualneKlient'].eq('1').mul(1)\n",
    "#X_yesno['BiuroWirtD'] = X_binary['BiuroWirtualneDostawca'].eq('1').mul(1)\n",
    "#X_yesno['BiuroWirtP'] = X_binary['BiuroWirtualnePosrednik'].eq('1').mul(1)\n",
    "X_yesno['Czy_leas_zwr'] = X_bin['Czy_leasing_zwrotny'].astype(float)\n",
    "X_yesno['Wyn_spraw_KRD'] = X_bin['Wynik_sprawdzen_KRD'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b320d86f",
   "metadata": {
    "id": "b320d86f"
   },
   "outputs": [],
   "source": [
    "# ----- ładowanie danych głównego kodu PKD ------\n",
    "# w tym przypadku wykorzystywane są tylko fragmenty PKD /sekcja, dział, grupa/\n",
    "#X_text_cat['kodpkd'] = X_text_cat['PKD_2007'].str.get(0)+X_text_cat['PKD_2007'].str.get(1)+X_text_cat['PKD_2007'].str.get(2)\n",
    "dset['kodpkd'] = dset['PKD_2007'].str.get(0)+dset['PKD_2007'].str.get(1)+dset['PKD_2007'].str.get(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3cba5597",
   "metadata": {
    "id": "3cba5597"
   },
   "outputs": [],
   "source": [
    "# ---- ładowanie danych rodzaj umowy; oddział; grupowanie form prawnych; branza; OBT_Type2 (czyli rodzaj przedmiotu lisingu)\n",
    "#zaminić dset na zmienną X_text_cat - zrobić\n",
    "dset['rodzumowy'] = dset['Rodzaj_umowy'].astype(str)\n",
    "dset['oddzial1'] = dset['Oddzial'].astype(str)\n",
    "dset['oddzial1'] = dset['oddzial1'].str.replace(' ', '')\n",
    "dset['oddzial1'] = dset['oddzial1'].str.replace('-', '')\n",
    "dset['oddzial1'] = dset['oddzial1'].str.strip()\n",
    "dset['grupowanie'] = dset['Grupowanie_form_prawnych'].astype(str)\n",
    "dset['branza1'] = dset['Branza'].astype(str)\n",
    "dset['OBT_Type2'] = dset['OBT_Type2'].str.replace(' ', '')\n",
    "dset['OBT_Type2'] = dset['OBT_Type2'].str.replace('&', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "877a8bda",
   "metadata": {
    "id": "877a8bda"
   },
   "outputs": [],
   "source": [
    "# ---- ładowanie danych z bazy danych z tabeli cechy scoringowe\n",
    "#X_scor = pd.DataFrame(dset.iloc[:, 35:92].values.astype(int)) # 57 kolumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "383a81b2",
   "metadata": {
    "id": "f2664bed"
   },
   "outputs": [],
   "source": [
    "tdset = pd.read_csv('data/probkatestowa2.csv', sep=';',encoding='utf-8')\n",
    "del tdset['Data_bilansowa']\n",
    "\n",
    "tY = tdset['Default'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74123a1f",
   "metadata": {
    "id": "74123a1f"
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(data, column, size):\n",
    "    encoder = OneHotEncoder(sparse_output=False)\n",
    "    encoded_data = encoder.fit_transform(data[[column]])\n",
    "    encoded_df = pd.DataFrame(encoded_data, columns=[f'{column}_{i}' for i in range(encoded_data.shape[1])])\n",
    "    return encoded_df\n",
    "\n",
    "def apply_hash(data, column, size):\n",
    "    encoded_hash = [hash(str(d)) % size for d in data[column]]\n",
    "    encoded_hash_df = pd.DataFrame(encoded_hash, columns=[f'{column}_hash'])\n",
    "    return encoded_hash_df\n",
    "\n",
    "# One-Hot Encoding dla 'pkd'\n",
    "pkd_size = 272\n",
    "X_pkd = one_hot_encode(dset, 'kodpkd', pkd_size)\n",
    "\n",
    "# Hashing Trick dla 'pkd'\n",
    "X_pkd_hash = apply_hash(dset, 'kodpkd', pkd_size)\n",
    "\n",
    "# One-Hot Encoding dla 'rodzumowy'\n",
    "rumowy_size = 4\n",
    "X_rumowy = one_hot_encode(dset, 'rodzumowy', rumowy_size)\n",
    "\n",
    "# Hashing Trick dla 'rodzumowy'\n",
    "X_rumowy_hash = apply_hash(dset, 'rodzumowy', rumowy_size)\n",
    "\n",
    "# One-Hot Encoding dla 'grupowanie'\n",
    "grupowanie_size = 4\n",
    "X_grupowanie = one_hot_encode(dset, 'grupowanie', grupowanie_size)\n",
    "\n",
    "# Hashing Trick dla 'grupowanie'\n",
    "X_grupowanie_hash = apply_hash(dset, 'grupowanie', grupowanie_size)\n",
    "\n",
    "# One-Hot Encoding dla 'oddzial1'\n",
    "oddzial1_size = 24\n",
    "X_oddzial1 = one_hot_encode(dset, 'oddzial1', oddzial1_size)\n",
    "\n",
    "# Hashing Trick dla 'oddzial1'\n",
    "X_oddzial1_hash = apply_hash(dset, 'oddzial1', oddzial1_size)\n",
    "\n",
    "# One-Hot Encoding dla 'branza1'\n",
    "branza1_size = 7\n",
    "X_branza1 = one_hot_encode(dset, 'branza1', branza1_size)\n",
    "\n",
    "# Hashing Trick dla 'branza1'\n",
    "X_branza1_hash = apply_hash(dset, 'branza1', branza1_size)\n",
    "\n",
    "# One-Hot Encoding dla 'OBT_Type2'\n",
    "objlise_size = 7\n",
    "X_objlise = one_hot_encode(dset, 'OBT_Type2', objlise_size)\n",
    "\n",
    "# Hashing Trick dla 'OBT_Type2'\n",
    "X_objlise_hash = apply_hash(dset, 'OBT_Type2', objlise_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58a86b5d",
   "metadata": {
    "id": "58a86b5d"
   },
   "outputs": [],
   "source": [
    "#print(tdset)\n",
    "\n",
    "tX = tdset.loc[:, columnX].astype(float)\n",
    "# usuwa Null z 3 kolumn\n",
    "\n",
    "tX['Kapital'] = tX['Kapital'].fillna(0)\n",
    "\n",
    "tscaler = StandardScaler()\n",
    "\n",
    "# Standaryzacja wszystkich zmiennych w dataframe X\n",
    "tX_standardized = scaler.fit_transform(tX)\n",
    "# Tworzenie nowego dataframe z zstandaryzowanymi danymi\n",
    "tX_standardized_df = pd.DataFrame(tX_standardized, columns=tX.columns)\n",
    "\n",
    "# Tworzenie obiektu MinMaxScaler\n",
    "tscaler_minmax = MinMaxScaler()\n",
    "\n",
    "# Normalizacja min-max dla zmiennych z X_discrete\n",
    "for column_name in X_discrete:\n",
    "    tdset[column_name] = scaler_minmax.fit_transform(tdset[[column_name]])\n",
    "\n",
    "tX_bin = tdset.loc[:,['Czy_cesja', 'Czy_leasing_zwrotny', 'Wynik_sprawdzen_KRD']].astype(str)\n",
    "\n",
    "tX_yesno = pd.DataFrame(tX_bin['Czy_cesja'].eq('1').mul(1))\n",
    "#tX_yesno['Czy_aut_dostawca'] = tX_binary['Czy_autoryzowany_dostawca'].eq('T').mul(1)\n",
    "#tX_yesno['Waluta'] = tX_binary['Waluta'].eq('PLN').mul(1)\n",
    "#tX_yesno['Rodzaj_harm'] = tX_binary['Rodzaj_harmonogramu'].eq('liniowy').mul(1)\n",
    "#tX_yesno['Rodzaj_oproc'] = tX_binary['Rodzaj_oprocentowania'].eq('V').mul(1)\n",
    "#tX_yesno['Dodat_zabezp_trans'] = tX_binary['Dodatkowe_zabezpieczenie_transakcji'].eq('WEKSEL').mul(1)\n",
    "#tX_yesno['Kanal_pozysk'] = tX_binary['Kanal_pozyskania'].eq('Porednik').mul(1)\n",
    "#tX_yesno['Cesja'] = tX_bin['Czy_cesja'].eq('1').mul(1)\n",
    "#tX_yesno['Auto_luks'] = tX_binary['Auto_luksusowe'].eq('1').mul(1)\n",
    "#tX_yesno['RSEUO'] = tX_binary['RS_EUO'].eq('1').mul(1)\n",
    "#tX_yesno['BiuroWirtK'] = tX_binary['BiuroWirtualneKlient'].eq('1').mul(1)\n",
    "#tX_yesno['BiuroWirtD'] = tX_binary['BiuroWirtualneDostawca'].eq('1').mul(1)\n",
    "#tX_yesno['BiuroWirtP'] = tX_binary['BiuroWirtualnePosrednik'].eq('1').mul(1)\n",
    "tX_yesno['Czy_leas_zwr'] = tX_bin['Czy_leasing_zwrotny'].astype(float)\n",
    "tX_yesno['Wyn_spraw_KRD'] = tX_bin['Wynik_sprawdzen_KRD'].astype(float)\n",
    "tdset['kodpkd'] = tdset['PKD_2007'].str.get(0)+tdset['PKD_2007'].str.get(1)+tdset['PKD_2007'].str.get(2)\n",
    "\n",
    "tdset['rodzumowy'] = tdset['Rodzaj_umowy'].astype(str)\n",
    "tdset['oddzial1'] = tdset['Oddzial'].astype(str)\n",
    "tdset['oddzial1'] = tdset['oddzial1'].str.replace(' ', '')\n",
    "tdset['oddzial1'] = tdset['oddzial1'].str.replace('-', '')\n",
    "tdset['oddzial1'] = tdset['oddzial1'].str.strip()\n",
    "tdset['grupowanie'] = tdset['Grupowanie_form_prawnych'].astype(str)\n",
    "tdset['branza1'] = tdset['Branza'].astype(str)\n",
    "tdset['OBT_Type2'] = tdset['OBT_Type2'].str.replace(' ', '')\n",
    "tdset['OBT_Type2'] = tdset['OBT_Type2'].str.replace('&', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c43fe11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(data, column, size):\n",
    "    encoder = OneHotEncoder(sparse_output=False)\n",
    "    encoded_data = encoder.fit_transform(data[[column]])\n",
    "    encoded_df = pd.DataFrame(encoded_data, columns=[f'{column}_{i}' for i in range(encoded_data.shape[1])])\n",
    "    return encoded_df\n",
    "\n",
    "def apply_hash(data, column, size):\n",
    "    encoded_hash = [hash(str(d)) % size for d in data[column]]\n",
    "    encoded_hash_df = pd.DataFrame(encoded_hash, columns=[f'{column}_hash'])\n",
    "    return encoded_hash_df\n",
    "\n",
    "# One-Hot Encoding dla 'pkd'\n",
    "tX_pkd = one_hot_encode(dset, 'kodpkd', pkd_size)\n",
    "\n",
    "# Hashing Trick dla 'pkd'\n",
    "tX_pkd_hash = apply_hash(dset, 'kodpkd', pkd_size)\n",
    "\n",
    "# One-Hot Encoding dla 'rodzumowy'\n",
    "tX_rumowy = one_hot_encode(dset, 'rodzumowy', rumowy_size)\n",
    "\n",
    "# Hashing Trick dla 'rodzumowy'\n",
    "tX_rumowy_hash = apply_hash(dset, 'rodzumowy', rumowy_size)\n",
    "\n",
    "# One-Hot Encoding dla 'grupowanie'\n",
    "tX_grupowanie = one_hot_encode(dset, 'grupowanie', grupowanie_size)\n",
    "\n",
    "# Hashing Trick dla 'grupowanie'\n",
    "tX_grupowanie_hash = apply_hash(dset, 'grupowanie', grupowanie_size)\n",
    "\n",
    "# One-Hot Encoding dla 'oddzial1'\n",
    "tX_oddzial1 = one_hot_encode(dset, 'oddzial1', oddzial1_size)\n",
    "\n",
    "# Hashing Trick dla 'oddzial1'\n",
    "tX_oddzial1_hash = apply_hash(dset, 'oddzial1', oddzial1_size)\n",
    "\n",
    "# One-Hot Encoding dla 'branza1'\n",
    "tX_branza1 = one_hot_encode(dset, 'branza1', branza1_size)\n",
    "\n",
    "# Hashing Trick dla 'branza1'\n",
    "tX_branza1_hash = apply_hash(dset, 'branza1', branza1_size)\n",
    "\n",
    "# One-Hot Encoding dla 'OBT_Type2'\n",
    "tX_objlise = one_hot_encode(dset, 'OBT_Type2', objlise_size)\n",
    "\n",
    "# Hashing Trick dla 'OBT_Type2'\n",
    "tX_objlise_hash = apply_hash(dset, 'OBT_Type2', objlise_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "05831812",
   "metadata": {
    "id": "05831812"
   },
   "outputs": [],
   "source": [
    "#------------------------ Model sztucznej sieci neuronowej (ANN)-----------------------------------------------------------\n",
    "\n",
    "\n",
    "inputpkd = Input(shape=(1,), name='in_pkd')\n",
    "pkd = Embedding(pkd_size, 10, input_length=1)(inputpkd)\n",
    "pkd_out = Flatten()(pkd)\n",
    "pkd_out = Dense(200, activation='relu')(pkd_out)\n",
    "\n",
    "inputrumowy = Input(shape=(1,), name='in_rodzaj_umowy')\n",
    "rumowy = Embedding(rumowy_size, 3, input_length=1)(inputrumowy)\n",
    "rumowy_out = Flatten()(rumowy)\n",
    "rumowy_out = Dense(100, activation='relu')(rumowy_out)\n",
    "\n",
    "inputgrupowanie = Input(shape=(1,), name='in_grupowanie')\n",
    "grupowanie = Embedding(grupowanie_size, 3, input_length=1)(inputgrupowanie)\n",
    "grupowanie_out = Flatten()(grupowanie)\n",
    "grupowanie_out = Dense(100, activation='relu')(grupowanie_out)\n",
    "\n",
    "inputoddzial1 = Input(shape=(1,), name='in_oddzial1')\n",
    "oddzial1 = Embedding(oddzial1_size, 10, input_length=1)(inputoddzial1)\n",
    "oddzial1_out = Flatten()(oddzial1)\n",
    "oddzial1_out = Dense(100, activation='relu')(oddzial1_out)\n",
    "\n",
    "inputbranza1 = Input(shape=(1,), name='in_branza1')\n",
    "branza1 = Embedding(branza1_size, 4, input_length=1)(inputbranza1)\n",
    "branza1_out = Flatten()(branza1)\n",
    "branza1_out = Dense(100, activation='relu')(branza1_out)\n",
    "\n",
    "inputobjlise = Input(shape=(1,), name='in_lise_object')\n",
    "objlise = Embedding(objlise_size, 4, input_length=1)(inputobjlise)\n",
    "objlise_out = Flatten()(objlise)\n",
    "objlise_out = Dense(100, activation='relu')(objlise_out)\n",
    "\n",
    "inputnumbers = Input(shape=(11,), name='in_continous')\n",
    "innum = Dense(200, activation=\"relu\")(inputnumbers)\n",
    "innum = BatchNormalization()(innum)\n",
    "num_out = Dense(100, activation=\"relu\")(innum)\n",
    "\n",
    "inputyesno = Input(shape=(3,), name='in_bool')\n",
    "inyesno = Dense(15, activation=\"relu\")(inputyesno)\n",
    "yesno_out = Dense(10, activation=\"relu\")(inyesno)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7750e3e0",
   "metadata": {
    "id": "7750e3e0"
   },
   "outputs": [],
   "source": [
    "merge = concatenate([pkd_out, num_out,rumowy_out,grupowanie_out, yesno_out, oddzial1_out, branza1_out, objlise_out], axis=-1)\n",
    "\n",
    "hidden = Dense(wynik1, activation='relu')(merge)\n",
    "hidden = BatchNormalization()(hidden)\n",
    "hidden = Dense(wynik2, activation='relu')(hidden)\n",
    "hidden = Dense(wynik3, activation='relu')(hidden)\n",
    "output = Dense(1, activation='sigmoid')(hidden)\n",
    "\n",
    "model = Model(inputs=[inputpkd,  inputnumbers, inputrumowy, inputgrupowanie, inputyesno, inputoddzial1,  inputbranza1, inputobjlise], outputs=output)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "431ec7eb-8ca1-404b-978c-fc5ffa6fdf41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Definiowanie tablic do połączenia\n",
    "arrays = [X_pkd, X_pkd_hash, X_rumowy, X_rumowy_hash, X_grupowanie, X_grupowanie_hash, X_oddzial1, X_oddzial1_hash, X_branza1, X_branza1_hash, X_objlise, X_objlise_hash]\n",
    "\n",
    "# Łączenie tablic wzdłuż drugiej osi\n",
    "t_arrays = [tX_pkd, tX_pkd_hash, tX_rumowy, tX_rumowy_hash, tX_grupowanie, tX_grupowanie_hash, tX_oddzial1, tX_oddzial1_hash, tX_branza1, tX_branza1_hash, tX_objlise, tX_objlise_hash]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0387520e-3ec6-40d7-9cbb-b07afd8956b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 219 and the array at index 1 has size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_combined \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack(arrays)\n\u001b[0;32m      2\u001b[0m tX_combined \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack(t_arrays)\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mvstack\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\core\\shape_base.py:296\u001b[0m, in \u001b[0;36mvstack\u001b[1;34m(tup, dtype, casting)\u001b[0m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arrs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    295\u001b[0m     arrs \u001b[38;5;241m=\u001b[39m [arrs]\n\u001b[1;32m--> 296\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _nx\u001b[38;5;241m.\u001b[39mconcatenate(arrs, \u001b[38;5;241m0\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype, casting\u001b[38;5;241m=\u001b[39mcasting)\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 219 and the array at index 1 has size 1"
     ]
    }
   ],
   "source": [
    "X_combined = np.vstack(arrays)\n",
    "tX_combined = np.vstack(t_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fdb78f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of arrays:\n",
      "(10000, 219)\n",
      "(10000, 1)\n",
      "(10000, 4)\n",
      "(10000, 1)\n",
      "(10000, 6)\n",
      "(10000, 1)\n",
      "(10000, 23)\n",
      "(10000, 1)\n",
      "(10000, 7)\n",
      "(10000, 1)\n",
      "(10000, 7)\n",
      "(10000, 1)\n",
      "Shape of t_arrays:\n",
      "(10000, 219)\n",
      "(10000, 1)\n",
      "(10000, 4)\n",
      "(10000, 1)\n",
      "(10000, 6)\n",
      "(10000, 1)\n",
      "(10000, 23)\n",
      "(10000, 1)\n",
      "(10000, 7)\n",
      "(10000, 1)\n",
      "(10000, 7)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of arrays:\")\n",
    "for arr in arrays:\n",
    "    print(arr.shape)\n",
    "    \n",
    "print(\"Shape of t_arrays:\")\n",
    "for arr in t_arrays:\n",
    "    print(arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5566a7a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'arrays' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Sprawdzenie rozmiarów tablic wejściowych\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m x_sizes \u001b[38;5;241m=\u001b[39m [arr\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m      5\u001b[0m y_size \u001b[38;5;241m=\u001b[39m Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Sprawdzenie, czy rozmiary są zgodne\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'arrays' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sprawdzenie rozmiarów tablic wejściowych\n",
    "x_sizes = [arr.shape[0] for arr in arrays]\n",
    "y_size = Y.shape[0]\n",
    "\n",
    "# Sprawdzenie, czy rozmiary są zgodne\n",
    "if len(set(x_sizes)) > 1 or any(size != y_size for size in x_sizes):\n",
    "    # Dostosowanie rozmiarów tablic\n",
    "    min_size = min(x_sizes + [y_size])\n",
    "    arrays = [arr[:min_size] for arr in arrays]\n",
    "    Y = Y[:min_size]\n",
    "\n",
    "# Trenowanie modelu\n",
    "h = model.fit(arrays, Y, validation_data=(t_arrays, tY), \n",
    "              epochs=num_epochs, \n",
    "              batch_size=batchsize)\n",
    "\n",
    "# Zapisanie modelu\n",
    "model.save_weights(\"model3_weights.h5\", overwrite=True)\n",
    "model.save('model3_structure.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d049cc53",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d049cc53",
    "outputId": "ef42a106-2fc2-4c5f-9dd4-0c4e87035fcf"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# One-Hot Encoding\n",
    "encoder = OneHotEncoder()\n",
    "encoder.fit(X_combined)\n",
    "X_encoded = encoder.transform(X_combined)\n",
    "tX_encoded = encoder.transform(tX_combined)\n",
    "\n",
    "# Podział danych na zbiór treningowy i walidacyjny\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_encoded, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tworzenie modelu\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_shape=(X_encoded.shape[1],)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Kompilacja modelu\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Trenowanie modelu\n",
    "start_time = time.time()\n",
    "model.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs=num_epochs, batch_size=batchsize)\n",
    "\n",
    "# Zapis modelu\n",
    "model.save_weights(\"model3_weights.h5\", overwrite=True)\n",
    "model.save('model3_structure.h5', overwrite=True)\n",
    "\n",
    "# Wyświetlenie czasu symulacji\n",
    "print(\"Czas symulacji:\", time.time() - start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24967b7b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "24967b7b",
    "outputId": "efc8ec26-0f70-41b1-aa72-da8e2dbb3514"
   },
   "outputs": [],
   "source": [
    "model.save_weights(\"model3_weights.h5\", overwrite=True)\n",
    "model.save('model3_structure.h5', overwrite=True)\n",
    "print(\"Czas symulacji: \", time.time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4AK4W6KGDEoS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4AK4W6KGDEoS",
    "outputId": "dfd1afa5-bc3e-423d-9d78-202c0bc1c6b7"
   },
   "outputs": [],
   "source": [
    "####użyć tylko raz, jak następny kod nie działa !!\n",
    "#df = pd.DataFrame()\n",
    "#file_name = 'wyniki_treningu.xlsx'\n",
    "#df.to_excel(file_name, index=False)\n",
    "#print(f\"Plik {file_name} został utworzony.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ghMUFxaaDOU_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ghMUFxaaDOU_",
    "outputId": "3d26e129-4f59-4229-e214-0dc7ed0d8011"
   },
   "outputs": [],
   "source": [
    "training_results = []\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    epoch_results = {\n",
    "        'loss': h.history['loss'][i],\n",
    "        'val_loss': h.history['val_loss'][i],\n",
    "        'val_accuracy': h.history['val_accuracy'][i],\n",
    "        'val_precision': h.history['val_precision'][i],\n",
    "        'val_recall': h.history['val_recall'][i],\n",
    "        'val_auc': h.history['val_auc'][i],\n",
    "        'czas_symulacji': time.time() - t\n",
    "    }\n",
    "\n",
    "    training_results.append(epoch_results)\n",
    "\n",
    "results_df = pd.DataFrame(training_results)\n",
    "\n",
    "title_epochs = f\"Wyniki treningu dla {num_epochs} epok\"\n",
    "title_1 = f\"Dense 1: {wynik1}\"\n",
    "title_2 = f\"Dense 2: {wynik2}\"\n",
    "title_3 = f\"Dense 3: {wynik3}\"\n",
    "\n",
    "sheet_name = f'Sheet_{int(time.time())}'\n",
    "\n",
    "with pd.ExcelWriter('wyniki_treningu.xlsx', engine='openpyxl', mode='a', if_sheet_exists='replace') as writer:\n",
    "    results_df.to_excel(writer, index=False, sheet_name=sheet_name)\n",
    "\n",
    "    worksheet = writer.sheets[sheet_name]\n",
    "\n",
    "    worksheet.cell(row=1, column=22, value=title_epochs)\n",
    "    worksheet.cell(row=2, column=22, value=title_1)\n",
    "    worksheet.cell(row=3, column=22, value=title_2)\n",
    "    worksheet.cell(row=4, column=22, value=title_3)\n",
    "\n",
    "print(results_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6bdab4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 537
    },
    "id": "9c6bdab4",
    "outputId": "078282fd-2e0f-4627-c9c2-022499facf00"
   },
   "outputs": [],
   "source": [
    "# dodatkowe elementy (można zakomentować); rysowanie wykresu dokładności ANN; Dokładnośc ANN dla Defaultów\n",
    "plt.plot(h.history['val_accuracy'])\n",
    "\n",
    "#plt.plot(h.history['accuracy'])\n",
    "\n",
    "#plt.plot(h.history['val_accuracy'])\n",
    "\n",
    "#plt.title('Model accuracy')\n",
    "\n",
    "#plt.ylabel('Accuracy')\n",
    "\n",
    "#plt.xlabel('Epoch')\n",
    "\n",
    "#plt.legend(['Train', 'Test'], loc='upper left')\n",
    "\n",
    "\n",
    "\n",
    "accuracy = model.evaluate([np.array(tX_pkd),np.array(tX), np.array(tX_rumowy), np.array(tX_grupowanie), np.array(tX_yesno),\n",
    "                           np.array(tX_oddzial1), np.array(tX_branza1), np.array(tX_objlise)], tY)\n",
    "print('Accuracy: %f' % (accuracy[1]))\n",
    "\n",
    "ypred = model.predict([np.array(tX_pkd),np.array(tX), np.array(tX_rumowy), np.array(tX_grupowanie), np.array(tX_yesno),\n",
    "                           np.array(tX_oddzial1), np.array(tX_branza1), np.array(tX_objlise)])\n",
    "\n",
    "count = 0\n",
    "total = 0\n",
    "for i in range(len(ypred)):\n",
    "    if tY[i] == 1:\n",
    "        total = total + 1\n",
    "        if ypred[i][0] > 0.5:\n",
    "            count = count + 1\n",
    "print(\"dokładność [1]: \", count/total)\n",
    "\n",
    "count = 0\n",
    "total = 0\n",
    "for i in range(len(ypred)):\n",
    "    if tY[i] == 0:\n",
    "        total = total + 1\n",
    "        if ypred[i][0] < 0.5:\n",
    "            count = count + 1\n",
    "print(\"dokładność [0]: \", count/total)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d5b9d6",
   "metadata": {
    "id": "45d5b9d6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655d6105",
   "metadata": {
    "id": "655d6105"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
